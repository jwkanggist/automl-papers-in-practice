# AutoML
This repository is for collecting AutoML papers


## Noisy Label Problem

##### Problem Statements
- 2014 | A Comprehensive Introduction to Label Noise | Benoît Frénay, et al. | ESANN | [`PDF`](https://pdfs.semanticscholar.org/c44f/388832d6f309b1bb9ccdeddee491f195e6cd.pdf)

###### Adversarial ML
- 2014 | Intriguing properties of neural networks | C. Szegedy, et al. | ICLR |  [`PDF`](https://arxiv.org/pdf/1312.6199.pdf)
- 2015 | Explaining and harnessing adversarial examples | I. J. Goodfellow et al.| ICLR |  [`PDF`](https://arxiv.org/pdf/1412.6572.pdf)
- 2017 | Adversarial machine learning at scale | A. Kurakin et al. | ICLR |   [`PDF`](https://arxiv.org/pdf/1611.01236.pdf)
- 2017 | Adversarial examples in the physical world | A. Kurakin et al. | ICLR |   [`PDF`](https://arxiv.org/pdf/1607.02533.pdf)
- 2017 | Towards Deep Learning Models Resistant to Adversarial Attacks | Aleksander Madry etal | ICLR | [`PDF`](https://arxiv.org/abs/1706.06083)
- 2017 | Towards Evaluating the Robustness of Neural Networks | Nicholas Carlini, David Wagner | [`PDF`](https://arxiv.org/abs/1608.04644)

- 2018 | Obfuscated Gradients Give a False Sense of Security: Circumventing Defenses to Adversarial Examples | Anish Athalye et al. | ICML |  [`PDF`](https://arxiv.org/pdf/1802.00420.pdf)


###### Memorization Effect from Corrupted Labels
- 2017 | A Closer Look at Memorization in Deep Networks | D. Arpit, et al. | ICML | [`PDF`](https://arxiv.org/pdf/1706.05394.pdf)
- 2018 | Dimensionality-Driven Learning with Noisy Labels | X. Ma  et al. | ICML | [`PDF`](https://arxiv.org/pdf/1806.02612.pdf)
- 2019 | Searching to Exploit Memorization Effect in Learning from Corrupted Labels | Hansi Yang et al | Not published | [`PDF`](https://arxiv.org/pdf/1911.02377.pdf)


##### Curriculum Learning (model driven)
- 2009 | Curriculum Learning  | Yoshua Bengio et al. | ICML 2009 | [`PDF`](https://ronan.collobert.com/pub/matos/2009_curriculum_icml.pdf)
- 2018 | Mentornet:Learning data-driven curriculum for very deep neural networks on corrupted labels | Lu Jiang, et al. | ICML | [`PDF`](https://arxiv.org/pdf/1712.05055.pdf)
- 2018 | Co-teaching: Robust Training of Deep Neural Networks with Extremely Noisy Labels | Bo Han, et al. | NIPS | [`PDF`](https://arxiv.org/pdf/1804.06872.pdf)
- 2018 | Curriculum Learning by Transfer Learning: Theory and Experiments with Deep Network |  ICML 2018 | [`ArXiv`](https://arxiv.org/abs/1802.03796)
<!--- 2019 | Curriculum Learning for Domain Adaptation in Neural Machine Translation | [`ArXiv`](https://arxiv.org/abs/1905.05816)-->
<!--- 2019 | On The Power of Curriculum Learning in Training Deep Networks | [`ArXiv`](https://arxiv.org/abs/1904.03626)-->
- 2019 | Deep Self-Learning From Noisy Labels | Jiangfan Han et al. | CVPR 2019 | [`CVPROpenAccess`](http://openaccess.thecvf.com/content_ICCV_2019/html/Han_Deep_Self-Learning_From_Noisy_Labels_ICCV_2019_paper.html)
- 2019 | Learning to Learn From Noisy Labeled Data | J. Li et al. | CVPR 2019 | [`CVPROpenAccess`](http://openaccess.thecvf.com/content_CVPR_2019/html/Li_Learning_to_Learn_From_Noisy_Labeled_Data_CVPR_2019_paper.html)


##### Noisy Label Supervision (Loss based)
- 2017 | Making Deep Neural Networks Robust to Label Noise: A Loss Correction Approach | G Partini | CVPR 2017 |  [`ArXiv`](https://arxiv.org/abs/1609.03683)
- 2017 | Training deep neural-networks using a noise adaptation layer | J
<!--- 2017 | Learning From Noisy Large-Scale Datasets With Minimal Supervision | Andreas Veit et al. | CVPR 2017 | [`ArXiv`](https://arxiv.org/abs/1701.01619)-->
<!--- 2017 | Label-Free Supervision of Neural Networks with Physics and Domain Knowledge | R Stewart et al. | AAAI 2018 |  [`ArXiv`](https://arxiv.org/abs/1609.05566)-->
- 2018 | Masking: A new perspective of noisy supervision | Bo Han et al. | NIPS 2018 | [`NIPSProc`](http://papers.nips.cc/paper/7825-masking-a-new-perspective-of-noisy-supervision)

- 2018 | Learning from noisy singly-labeled data| Ashish Khetan, et al. | ICLR | [`PDF`](https://arxiv.org/abs/1712.04577.pdf)
- 2018 | Generalized Cross Entropy Loss for Training Deep Neural Networks with Noisy Labels | Zhilu Zhang, et al. | NIPS | [`PDF`](https://arxiv.org/pdf/1805.07836.pdf)

- 2019 | Learning with Bad Training Data via Iterative Trimmed Loss Minimization| Yanyao Shen, et al. | ICML | [`PDF`](https://arxiv.org/abs/1810.11874.pdf)
- 2019 | Learning with Limited Data for Multilingual Reading Comprehension | Kyungjae Lee et al. | EMNLP2019 | [`EMNLP2019`]( https://www.aclweb.org/anthology/D19-1283/)


##### Meta learning Approach
- 2018 | Learning to Reweight Examples for Robust Deep Learning | Mengye Ren, et al. | ICML | [`PDF`](https://arxiv.org/pdf/1803.09050.pdf)



##### Ensemble for Out of Distiribution
- 2017 | (DeepMind) Simple and Scalable Predictive Uncertainty Estimation using Deep Ensemble | Balaji Lakshminarayanan et al. | NIPS |  [`PDF`](http://papers.nips.cc/paper/7219-simple-and-scalable-predictive-uncertainty-estimation-using-deep-ensembles.pdf) 


## Active Learning
- 2019 | Learning Loss for Active Learning | Donggeun Yoo et al. | CVPR  | [`PDF`](https://arxiv.org/abs/1905.03677) [`Slide`](https://drive.google.com/file/d/1r1I6OrVYI_xofbLcnfUn7hhrx6Ta2oE5/view)
- 2010 | Active Learning Literature Survey - Chap1,2 | Burr Settles | University of Wisconsin–Madison | [`PDF`](http://burrsettles.com/pub/settles.activelearning.pdf)
- 2010 | Active Learning Literature Survey - Chap3 | Burr Settles | University of Wisconsin–Madison | [`PDF`](http://burrsettles.com/pub/settles.activelearning.pdf)
- 2017 | Learning Active Learning from Data

<!--## Hyperparameter Optimization-->

<!--##### Overview-->
<!--- 2019 |  [Blog - Hyper-parameter optimization algorithms: a short review](https://medium.com/criteo-labs/hyper-parameter-optimization-algorithms-2fe447525903#de39) | Aloïs Bissuel-->


<!--##### Bayesian Optimization and Gaussian process based-->
<!--- 2018 | A Tutorial on Bayesian Optimization | Peter I. Frazier. | ArXiv | [`PDF`](https://arxiv.org/pdf/1807.02811.pdf) [`Blog`](http://krasserm.github.io/2018/03/21/bayesian-optimization/)-->


<!--##### Population based-->
<!--- 2017 | Population Based Training of Neural Networks | Jaderberg et al. | ArXiv | [`PDF`](https://arxiv.org/abs/1711.09846) -->


<!--## Model Ensemble-->
<!--- 2017 | (DeepMind) Simple and Scalable Predictive Uncertainty Estimation using Deep Ensemble | Balaji Lakshminarayanan et al. | NIPS |  [`PDF`](http://papers.nips.cc/paper/7219-simple-and-scalable-predictive-uncertainty-estimation-using-deep-ensembles.pdf) -->




<!--## Intent/slot Clustering-->
<!--- 2018 | Auto-Dialabel: Labeling Dialogue Data with Unsupervised Learning | Chen Shi, et al. | EMNLP | [`PDF`](https://www.aclweb.org/anthology/D18-1072) [`Marco Slide`](https://docs.google.com/presentation/d/1FZiURnMyv7F7aEuCtZLx-f-bezVaCAUTO2ftBqRdR8Y/edit#slide=id.p) (Presenter: Jaewook Kang@ 190629)-->

## Data Profiling
- 2012 | The Influence of Corpus Quality on Statistical Measurements on Language Resources | Thomas Eckart et al. | [LREC 2012 proceeding](http://www.lrec-conf.org/proceedings/lrec2012/pdf/476_Paper.pdf)



<!--## Backdoor Attack Problem-->
<!--##### Problem Overview-->
<!--- 2019 | BadNets: Identifying Vulnerabilities in the Machine Learning Model Supply Chain | Tianyu Gu, et al. | arXiv | [`PDF`](https://arxiv.org/pdf/1708.06733.pdf)-->


<!--### Methods-->
<!--- 2018 | Fine-Pruning: Defending Against Backdooring Attacks on Deep Neural Networks| Kang Liu, et al. | arXiv | [`PDF`](https://arxiv.org/abs/1805.12185)-->
<!--- 2018 | Detecting Backdoor Attacks on Deep Neural Networks by Activation Clustering | Bryant Chen, et al. | arXiv | [`PDF`](https://arxiv.org/pdf/1811.03728.pdf)-->

<!--## ML Fairness Problem-->

<!--##### Problem Overview-->
<!--- 2016 | Equality of Opportunity in Supervised Learning| Moritz Hardt, et al. | NIPS | [`PDF`](https://arxiv.org/pdf/1610.02413.pdf)-->

<!--##### Methods-->
<!--- 2019 | Identifying and Correcting Label Bias in Machine Learning| Heinrich Jiang, et al. | arXiv | [`PDF`](https://arxiv.org/pdf/1901.04966.pdf)-->


## Acknowledgement
Special thanks to everyone who contributed to this project.

| Name       | Bio        |
| :--------: | :--------: |
| [Jaewook Kang](https://github.com/jwkanggist) | Research Scientist @Naver Clova |


## Contact & Feedback
If you have any suggestions (missing papers, new papers, key researchers or typos), feel free to pull a request. Also you can mail to:
+ Jaewook Kang (jwkang10@gmail.com).


